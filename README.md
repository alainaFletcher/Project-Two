# Project-Two

## Objective

Create a Spark Application that process Covid data. Your project  should involve some analysis of covid data(Every concept of spark from rdd, dataframes, sql, dataset and optimization methods should be included, persistence also).  The final expected output is different trends that you have observed as part of data collectivley and how can WHO make use of these trends to make some useful decisions.  Lets the P2 Demo, have presentation with screen shots and practical demo for at least one of your trends.

## Technologies Used

* Dataframes: represents a table of data with rows and columns. The list of columns and the types in those columns the schema. 
* Datasets: type-safe version of Sparkâ€™s structured API for Java and Scala. 
* Spark SQL: a Spark module for structured data processing.
* Scala:  statically typed general-purpose programming language which supports both object-oriented programming and functional programming. 
* Spark: unified analytics engine for big data and machine learning. 
* Hadoop: a collection of open-source software utilities applied to big data.

    
## Features 
* Communicate and coordinate with training peers
* Establish github repo and plan frame work of project
* Generate dataframes, datasets, and rdds from the provided .csv files
* Develop spark sql queries to extract the desired data
* Observed the death rates across ten countreis.
* Query dataframes to observe trends in deaths within the US during the holiday season (November 28- January 1)
* Query dataframes to determine the states with the highest death rates.
* Query dataframes to compare the death to recovery ratio between April 2020 and April 2021
* Generate graphical representation of observed data
*  Present and communicate results alongside training peers

